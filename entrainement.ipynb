{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "3310171a76644f05622fcb64d5baf05272e788f46f16892b1e99ee9aad5da057"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# MLflow Training Tutorial (la copie)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(labels_array, nb_epochs, nb_patience):\n",
    "\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, GlobalMaxPooling2D, MaxPooling2D, AveragePooling2D, Activation, Dropout, Flatten, Dense\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "\n",
    "    import mlflow\n",
    "    import mlflow.tensorflow\n",
    "\n",
    "    # Telechargement du ZIP\n",
    "    from modules.loader import Loader\n",
    "\n",
    "    loader = Loader(\n",
    "        \"https://stdatalake010.blob.core.windows.net/public/cifar-100.zip\",\n",
    "        '../datas/ZIP/',\n",
    "        extraction_target='../datas/RAW/'\n",
    "    )\n",
    "    loader.ensure_data_loaded()\n",
    "\n",
    "    # Extraction du jeu de donnees\n",
    "    from modules.splitting import Splitting\n",
    "\n",
    "    labels_array = ['apple', 'bee']\n",
    "\n",
    "    TRAIN_DATA_DIR = Splitting.copie_dossiers(\n",
    "        '../datas/RAW/train',\n",
    "        labels_array,\n",
    "        500,\n",
    "        explorer=False\n",
    "    )\n",
    "\n",
    "    print(TRAIN_DATA_DIR)\n",
    "\n",
    "    # Chargement des images\n",
    "    image_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2)\n",
    "    TRAIN_IMAGE_SIZE = 32\n",
    "    TRAIN_BATCH_SIZE = 64\n",
    "\n",
    "    train_generator = image_data_generator.flow_from_directory(\n",
    "        TRAIN_DATA_DIR,\n",
    "        target_size=(TRAIN_IMAGE_SIZE, TRAIN_IMAGE_SIZE),\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "    \n",
    "    validation_generator = image_data_generator.flow_from_directory(\n",
    "        TRAIN_DATA_DIR, # same directory as training data\n",
    "        target_size=(TRAIN_IMAGE_SIZE, TRAIN_IMAGE_SIZE),\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=3, activation='elu', kernel_initializer='he_uniform', padding='same', input_shape=(32,32,3)))\n",
    "        #Toujours à la fin\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        es_callback = EarlyStopping(monitor='val_loss', patience=nb_patience)\n",
    "        training = model.fit(train_generator, epochs=nb_epochs, callbacks=[es_callback], validation_data=validation_generator, shuffle=False)\n",
    "        \n",
    "        # mlflow.log_param(\"labels_array\", labels_array)\n",
    "        # mlflow.log_param(\"nb_epochs\", nb_epochs)\n",
    "        # mlflow.log_param(\"nb_patience\", nb_patience)\n",
    "\n",
    "        # mlflow.log_metric(\"accuracy\", training.history['accuracy'])\n",
    "        # mlflow.log_metric(\"val_accuracy\", training.history['val_accuracy'])\n",
    "        # mlflow.log_metric(\"loss\", training.history['loss'])\n",
    "        # mlflow.log_metric(\"val_loss\", training.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Le fichier ZIP existe déjà\n",
      "Le dossier d:\\simplon\\datas\\RAW\\train_apple_bee existe déjà !\n",
      "d:\\simplon\\datas\\RAW\\train_apple_bee\n",
      "Found 800 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "2021/01/18 00:41:31 INFO mlflow.utils.autologging_utils: tensorflow autologging will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow to the MLflow run with ID 'cf4b8299f71a4337890694b3afe4d231'\n",
      "Epoch 1/15\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 52.3883 - accuracy: 0.3281WARNING:tensorflow:From D:\\ana_conda\\envs\\sandbox\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/13 [===>..........................] - ETA: 1s - loss: 1078.1162 - accuracy: 0.4297WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0391s vs `on_train_batch_end` time: 0.2256s). Check your callbacks.\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 426.5311 - accuracy: 0.6125 - val_loss: 71.2311 - val_accuracy: 0.8350\n",
      "Epoch 2/15\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 83.7408 - accuracy: 0.8000 - val_loss: 59.9882 - val_accuracy: 0.8500\n",
      "Epoch 3/15\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 31.6371 - accuracy: 0.8875 - val_loss: 52.6981 - val_accuracy: 0.8300\n",
      "Epoch 4/15\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 17.6167 - accuracy: 0.9162 - val_loss: 47.2200 - val_accuracy: 0.8250\n",
      "Epoch 5/15\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 10.6057 - accuracy: 0.9325 - val_loss: 32.0977 - val_accuracy: 0.8900\n",
      "Epoch 6/15\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 4.4314 - accuracy: 0.9712 - val_loss: 30.8961 - val_accuracy: 0.8900\n",
      "Epoch 7/15\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 2.7265 - accuracy: 0.9775 - val_loss: 26.1490 - val_accuracy: 0.8850\n",
      "Epoch 8/15\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 2.7528 - accuracy: 0.9737 - val_loss: 27.0242 - val_accuracy: 0.8750\n",
      "Epoch 9/15\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.1115 - accuracy: 0.9850 - val_loss: 22.0109 - val_accuracy: 0.8900\n",
      "Epoch 10/15\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 0.9436 - accuracy: 0.9875 - val_loss: 23.9264 - val_accuracy: 0.8900\n",
      "Epoch 11/15\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.4624 - accuracy: 0.9937 - val_loss: 23.9708 - val_accuracy: 0.8900\n",
      "Epoch 12/15\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.1626 - accuracy: 0.9950 - val_loss: 22.4926 - val_accuracy: 0.8850\n",
      "Epoch 13/15\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 0.0243 - accuracy: 0.9987 - val_loss: 24.0863 - val_accuracy: 0.9050\n"
     ]
    }
   ],
   "source": [
    "labels_array = ['apple', 'bee']\n",
    "nb_epochs = 15\n",
    "nb_patience = 4\n",
    "\n",
    "import mlflow\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "train(labels_array, nb_epochs, nb_patience)"
   ]
  }
 ]
}