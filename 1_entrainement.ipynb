{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "3310171a76644f05622fcb64d5baf05272e788f46f16892b1e99ee9aad5da057"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# MLflow Training Tutorial (la copie)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(labels_array, nb_epochs, nb_patience):\n",
    "\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, GlobalMaxPooling2D, MaxPooling2D, AveragePooling2D, Activation, Dropout, Flatten, Dense\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "\n",
    "    import mlflow\n",
    "    import mlflow.tensorflow\n",
    "\n",
    "    # Telechargement du ZIP\n",
    "    from modules.loader import Loader\n",
    "\n",
    "    loader = Loader(\n",
    "        \"https://stdatalake010.blob.core.windows.net/public/cifar-100.zip\",\n",
    "        '../datas/ZIP/',\n",
    "        extraction_target='../datas/RAW/'\n",
    "    )\n",
    "    loader.ensure_data_loaded()\n",
    "\n",
    "    # Extraction du jeu de donnees\n",
    "    from modules.splitting import Splitting\n",
    "\n",
    "    labels_array = ['apple', 'bee']\n",
    "\n",
    "    TRAIN_DATA_DIR = Splitting.copie_dossiers(\n",
    "        '../datas/RAW/train',\n",
    "        labels_array,\n",
    "        500,\n",
    "        explorer=False\n",
    "    )\n",
    "\n",
    "    print(TRAIN_DATA_DIR)\n",
    "\n",
    "    # Chargement des images\n",
    "    image_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2)\n",
    "    TRAIN_IMAGE_SIZE = 32\n",
    "    TRAIN_BATCH_SIZE = 64\n",
    "\n",
    "    train_generator = image_data_generator.flow_from_directory(\n",
    "        TRAIN_DATA_DIR,\n",
    "        target_size=(TRAIN_IMAGE_SIZE, TRAIN_IMAGE_SIZE),\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "    \n",
    "    validation_generator = image_data_generator.flow_from_directory(\n",
    "        TRAIN_DATA_DIR, # same directory as training data\n",
    "        target_size=(TRAIN_IMAGE_SIZE, TRAIN_IMAGE_SIZE),\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=3, activation='elu', kernel_initializer='he_uniform', padding='same', input_shape=(32,32,3)))\n",
    "        #Toujours à la fin\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        es_callback = EarlyStopping(monitor='val_loss', patience=nb_patience)\n",
    "        training = model.fit(train_generator, epochs=nb_epochs, callbacks=[es_callback], validation_data=validation_generator, shuffle=False)\n",
    "        mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Le fichier ZIP existe déjà\n",
      "Le dossier d:\\simplon\\datas\\RAW\\train_apple_bee existe déjà !\n",
      "d:\\simplon\\datas\\RAW\\train_apple_bee\n",
      "Found 800 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 654.0524 - accuracy: 0.4837 - val_loss: 121.9647 - val_accuracy: 0.7300\n",
      "Epoch 2/15\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 113.0606 - accuracy: 0.7450 - val_loss: 97.6988 - val_accuracy: 0.8050\n",
      "Epoch 3/15\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 40.0981 - accuracy: 0.8725 - val_loss: 50.1241 - val_accuracy: 0.8250\n",
      "Epoch 4/15\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 30.1505 - accuracy: 0.8775 - val_loss: 53.6862 - val_accuracy: 0.8350\n",
      "Epoch 5/15\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 19.2246 - accuracy: 0.9175 - val_loss: 32.8592 - val_accuracy: 0.8400\n",
      "Epoch 6/15\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 9.1440 - accuracy: 0.9513 - val_loss: 30.7044 - val_accuracy: 0.8450\n",
      "Epoch 7/15\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 6.2477 - accuracy: 0.9413 - val_loss: 30.2122 - val_accuracy: 0.8350\n",
      "Epoch 8/15\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 4.1019 - accuracy: 0.9675 - val_loss: 29.4024 - val_accuracy: 0.8400\n",
      "Epoch 9/15\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 4.9717 - accuracy: 0.9500 - val_loss: 25.7498 - val_accuracy: 0.8700\n",
      "Epoch 10/15\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 3.8299 - accuracy: 0.9613 - val_loss: 23.4120 - val_accuracy: 0.8500\n",
      "Epoch 11/15\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 2.0187 - accuracy: 0.9688 - val_loss: 25.7288 - val_accuracy: 0.8450\n",
      "Epoch 12/15\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 0.7484 - accuracy: 0.9862 - val_loss: 19.8453 - val_accuracy: 0.8450\n",
      "Epoch 13/15\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.3872 - accuracy: 0.9875 - val_loss: 21.1028 - val_accuracy: 0.8450\n",
      "Epoch 14/15\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 0.1011 - accuracy: 0.9950 - val_loss: 21.6086 - val_accuracy: 0.8600\n",
      "Epoch 15/15\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 21.6479 - val_accuracy: 0.8450\n"
     ]
    }
   ],
   "source": [
    "labels_array = ['apple', 'bee']\n",
    "nb_epochs = 15\n",
    "nb_patience = 4\n",
    "\n",
    "train(labels_array, nb_epochs, nb_patience)"
   ]
  }
 ]
}